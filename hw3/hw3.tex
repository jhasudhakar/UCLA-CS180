% Author: Zhehao Wang 404380075 zhehao@cs.ucla.edu

% Grammar package: http://tex.stackexchange.com/questions/24886/which-package-can-be-used-to-write-bnf-grammars

\documentclass{article}
\topmargin = 0in
\oddsidemargin = 0in
\evensidemargin = \oddsidemargin
\textwidth = 6.5in
\textheight = 8in
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{syntax}
\usepackage{graphicx}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\title{CS180 Homework 3}
\author{Zhehao Wang 404380075 (Dis 1B)}
\date{Apr 16, 2016}

\begin{document}
\maketitle

\begin{description}

\item[1]{Strongly connected components in a directed graph}
  
  (a) Prove SCC graph is a DAG.

  \textbf{Proof by contradiction:} assume that a path $s_i, ..., s_j, s_i$ exists in the SCC graph, where $s_k$ ($i \leq k \leq j$) are the newly created distinct SCC nodes.

  There exists a path from any node $p_i$ in SCC $s_i$ to any node $p_{i+1}$ in SCC $s_{i+1}$, since there exists a node $q_i$ in SCC $s_i$ that has a directed edge to a node $q_{i+i}$ in SCC $s_{i+1}$, and there exists a path from $p_i$ to $q_i$, $q_{i+1}$ to $p_{i+1}$.

  Applying the above conclusion repeatedly till we reach $s_j$, we have the conclusion there exists a path from any node $p_i$ in SCC $s_i$ to any node $p_j$ in SCC $s_j$. Similarly, we have there exists a path from any node $p_j$ in SCC $s_j$ to any node $p_i$ in $s_i$. Thus the nodes $p_i$ and $p_j$ should belong to the same SCC node which is the combination of SCC $s_i$ and $s_j$, and contradicts with the nodes being distinct in the assumption. And we have the directed SCC graph is acyclic, which makes it a DAG by definition.

  (b) The algorithm is given in alg \ref{alg:scc-graph}.

  \begin{algorithm}[h]
  \caption{SCC building algorithm}
  \label{alg:scc-graph}
    \begin{algorithmic}[1]
  
    \Function{DFS}{v, do\_label, smallest\_node, node\_remaining, node\_removed, SCC\_graph}
      \State $v.visited \gets true$
      \If {$do\_label = false$}
        \State $node\_remaining.remove(v)$
        \State $node\_removed.add(v)$
        \If {$v = smallest\_node$}
          \State $smallest\_node \gets node\_remaining.nextSmallest()$
        \EndIf
      \EndIf
      \For {$\{i | (v,i) \in E, i.visited = false\}$}
        \If {$do\_label = true$}
          \State $DFS(i, do\_label, smallest\_node, node\_remaining, node\_removed, SCC\_graph)$
        \Else
          \If {$i \in SCC\_graph$}
            \State $SCC\_graph.addEdge(v,i)$
          \Else
            \State $DFS(i, do\_label, smallest\_node, node\_remaining, node\_removed, SCC\_graph)$
          \EndIf
        \EndIf
      \EndFor
      \If {$do\_label$}
        \State $id \gets label(v)$
        \If {$id < smallest\_node$}
          \State $smallest\_node \gets v$
        \EndIf
      \EndIf
    \EndFunction

    \Function{getSCC}{G}
      \State $smallest\_node \gets nil$
      \State $DFS(G.firstNode(), true, smallest\_node, G.nodes, [], nil)$

      \State $smallest\_node\_copy \gets smallest\_node.copy()$
      \State $G.resetVisited()$
      \State $SCC\_graph \gets nil$
      \While {$G.node\_count > 0$}
        \State $G.resetVisited()$
        \State $node\_removed \gets []$
        \State $DFS(smallest\_node, false, smallest\_node\_copy, G.nodes, node\_removed, SCC\_graph)$
        \State $smallest\_node \gets smallest\_node\_copy$
        \State $SCC\_graph.addNode(node\_removed)$
      \EndWhile

      \State \Return $SCC\_graph$
    \EndFunction
    
    \end{algorithmic}
  \end{algorithm}

  \textbf{Time complexity:} $O(|E|)$

  \textbf{Correctness:}

\item[2]{Longest path in DAG}

  (a) algorithm is given in alg \ref{alg:longest-path-unweighted-dag}.

  \begin{algorithm}[h]
  \caption{Longest path in an unweighted DAG}
  \label{alg:longest-path-unweighted-DAG}
    \begin{algorithmic}[1]
  
    \Function{longestPath}{G}
      \State $nodeCount \gets len(V)$
      \State $sourceNodes \gets []$
      \For {$\{i|i \in V\}$}
        \If {$i.inDegree = 0$}
          \State $sourceNodes.add(i)$
        \EndIf
      \EndFor
      \State $length \gets 0$
      \While {$nodeCount > 0$}
        \State $newSourceNodes \gets []$
        \For {$\{i|i \in sourceNodes\}$}
          \For {$\{v|(v, i) \in E\}$}
            \State $v.inDegree \gets v.inDegree - 1$
            \If {$v.inDegree = 0$}
              \State $newSourceNodes.add(v)$
            \EndIf
          \EndFor
          \State $G.remove(i)$
          \State $nodeCount \gets nodeCount - 1$
        \EndFor
        \State $sourceNodes \gets newSourceNodes$
        \State $length \gets length + 1$
      \EndWhile
      \State \Return $length$
    \EndFunction
    
    \end{algorithmic}
  \end{algorithm}

  \textbf{Time complexity:} this algorithm is $O(|E|)$.

  \textbf{Correctness:} this algorithm does a similar thing as topological sort, except that it counts the steps needed to remove all the nodes, instead of labeling each removed nodes. The recursive idea is that length of longest path in a DAG $G$ is 1 + length of longest path in $G'$, where $G'$ is the remaining graph after all sources in $G$ are removed.

  (b) algorithm is given in alg \ref{alg:longest-path-weighted-dag}. Similar with the idea of problem (a), we base the algorithm on topological sort. We associate a weight with each node, and each time the algorithm removes a source node $i$, the nodes $j$ that it connects to will have new weight $w(j) = max(w(j), weight(i,j) + w(i))$. The largest weight in the DAG will be returned as the length of the longest path.

  \begin{algorithm}[h]
  \caption{Longest path in a weighted DAG}
  \label{alg:longest-path-weighted-DAG}
    \begin{algorithmic}[1]
  
    \Function{longestPath}{G}
      \State $nodeCount \gets len(V)$
      \State $sourceNodes \gets []$
      \For {$\{i|i \in V\}$}
        \If {$i.inDegree = 0$}
          \State $sourceNodes.add(i)$
          \State $i.length \gets 0$
        \EndIf
      \EndFor
      \State $maxLength \gets min\_real$
      \While {$nodeCount > 0$}
        \State $newSourceNodes \gets []$
        \For {$\{i|i \in sourceNodes\}$}
          \For {$\{v|(v, i) \in E\}$}
            \State $v.inDegree \gets v.inDegree - 1$
            \State $v.weight \gets max(v.weight, i.weight + w(v,i))$
            \If {$maxLength < v.weight$}
              \State {$maxLength \gets v.weight$}
            \EndIf
            \If {$v.inDegree = 0$}
              \State $newSourceNodes.add(v)$
            \EndIf
          \EndFor
          \State $G.remove(i)$
          \State $nodeCount \gets nodeCount - 1$
        \EndFor
        \State $sourceNodes \gets newSourceNodes$
      \EndWhile
      \State \Return $maxLength$
    \EndFunction
    
    \end{algorithmic}
  \end{algorithm}

  \textbf{Time complexity:} this algorithm is $O(|E|)$.

  \textbf{Correctness:} 

  (c) algorithm is given in alg \ref{alg:weighted-dag-job-scheduling}. Similar idea as in (b). 

  \begin{algorithm}[h]
  \caption{Weighted DAG job scheduling}
  \label{alg:weighted-dag-job-scheduling}
    \begin{algorithmic}[1]
  
    \Function{longestPath}{G}
      \State $nodeCount \gets len(V)$
      \State $sourceNodes \gets []$
      \For {$\{i|i \in V\}$}
        \If {$i.inDegree = 0$}
          \State $sourceNodes.add(i)$
          \State $i.length \gets 0$
        \EndIf
      \EndFor
      \While {$nodeCount > 0$}
        \State $newSourceNodes \gets []$
        \For {$\{i|i \in sourceNodes\}$}
          \For {$\{v|(v, i) \in E\}$}
            \State $v.inDegree \gets v.inDegree - 1$
            \State $v.weight \gets max(v.weight, i.weight + w(v,i))$
            
            \State $v.length$
            \If {$v.inDegree = 0$}
              \State $newSourceNodes.add(v)$
            \EndIf
          \EndFor
          \State $G.remove(i)$
          \State $nodeCount \gets nodeCount - 1$
        \EndFor
        \State $sourceNodes \gets newSourceNodes$
      \EndWhile
      \State \Return $sort(v.weight)$
    \EndFunction
    
    \end{algorithmic}
  \end{algorithm}

  \textbf{Time complexity:} this algorithm is $O(max(|E|, |V| \log |V|))$.

  \textbf{Correctness:} 

\item[3]{Optimal order of files}
  
  Algorithm is given in alg \ref{alg:optimal-order-of-files}, which is a greedy algorithm that orders files as $f_{t_1}...f_{t_n}$, such that for each $t_i > t_j$, $l_{t_i} \cot p_{t_i} \leq l_{t_j} \cot p_{t_j}$.

  \begin{algorithm}[h]
  \caption{Optimal order of files}
  \label{alg:optimal-order-of-files}
    \begin{algorithmic}[1]
  
    \Function{longestPath}{G}
      \For {${i|i \in files}$}
        \State $weightedFiles.adds(i.probability \cdot i.length)$
      \EndFor
      \State \Return $sort(weightedFiles)$
    \EndFunction
    
    \end{algorithmic}
  \end{algorithm}

  \textbf{Time complexity:} this algorithm is $O(n \log n)$, where $n$ is the number of files.

  \textbf{Correctness:} proof by the algorithm's greedy choice property and optimal substructure property.

  \textbf{Greedy choice property:} there exists an optimal solution $S=f_{t_1}...f_{t_n}$, such that $l_{t_1} \cot p_{t_1}$ is the largest among all jobs.

  % The assumed optimal solution takes a specific form, is this Ok in the proof; if not, is Ang's proof for maximum contatenation correct in dis 3? The idea of that one is bubble sorting, should be better described in the notes as well
  Proof: suppose $S'$ is an optimal solution with the sequence $f_{t'_1}f_{t'_2}...f_{t_{k-1}}f_{t_1}f_{t_{k+1}}...f_{t_n}$ where $t'_1 \neq t_1$. The average access time of $S'$ is 

  $$t(S') = \sum_{i=2}^{n}{((\sum_{j=1}^{i-1}{l_{t'_j}}) \cdot p_{t'_i})}$$

  Consider the solution $S''$ with $f_{t_1}$ and $f_{t_{k-1}}$ swapped, the difference between average access time of $S''$ and that of $S'$ is

  $$t(S') - t(S'') = p_{t_{k-1}} * l_{t_{k-1}} - p_{t_1} * l_{t_1} \geq 0$$

  Similarly, starting from $t(S'')$, each time we swap $f_{t_1}$ with its previous file, we'll have a smaller or equal access time than before. Thus the optimal solution should contain $f_{t_1}$ as its first element, whose $l_{t_1} \cot p_{t_1}$ is the smallest.

  \textbf{Optimal substructure property:} let $S=f_{t_1}...f_{t_n}$ be an optimal solution, then $S_1=f_{t_2}...f_{t_n}$ is the optimal solution for the sub problem without $f_{t_1}$.

  Proof by contradiction: assume there's a better solution $S'_1=f_{t''_2}...f_{t''_n}$, $t(S'_1)<t(S_1)$ for the sub problem without $f_{t_1}$. Then $S'=f_{t_1}S'_1$ has the average access time of $t(S')=t(S'_1) + l_{t_1} * (1-p_{t_1}) < t(S_1) + l_{t_1} * (1-p_{t_1}) = t(S)$, which contradicts with $S$ being the optimal solution for the original problem.

  With both properties, the greedy algorithm in question is correct.

\item[4]{Sorting from SC}
  


\end{description}

\end{document}
